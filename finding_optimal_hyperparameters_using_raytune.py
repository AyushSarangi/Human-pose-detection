# -*- coding: utf-8 -*-
"""finding optimal hyperparameters using  rayTune.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yHBdrOMkXkprMc3FKF8lRdYboWtJh1vF
"""

from google.colab import drive
drive.mount('/content/drive')

import torch
from torch.utils.data import DataLoader, Dataset, random_split
from torchvision import transforms, utils
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from PIL import Image
import os
import numpy as np
import json
import matplotlib.pyplot as plt
from torch.utils.data.dataloader import default_collate

from functools import partial
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import random_split
import torchvision
import torchvision.transforms as transforms
from ray import tune
from ray.train import Checkpoint
from ray.air import  session
from ray.tune.schedulers import ASHAScheduler

# Define the dataset class
class HumanPoseDataset(Dataset):
    def __init__(self, annotations, img_dir, transform=None):
        self.annotations = annotations
        self.img_dir = img_dir
        self.transform = transform

    def __len__(self):
        return len(self.annotations)

    def __getitem__(self, idx):
        img_key = list(self.annotations.keys())[idx]
        annotation_list = self.annotations[img_key]
        # Skip the image if there are no annotations
        if not annotation_list:
            return None
        # Use the first annotation for simplicity
        annotation = annotation_list[0]
        if not annotation['landmarks']:  # Check if landmarks are not empty
            return None
        img_name = os.path.join(self.img_dir, annotation['file'])
        image = Image.open(img_name).convert('RGB')
        original_image_size = image.size
        keypoints = annotation['landmarks']
        keypoints_array = np.array([[k['x'], k['y'], k['z'], k['visibility']] for k in keypoints])

        if self.transform:
            image = self.transform(image)

        sample = {'image': image, 'keypoints': keypoints_array, 'original_image_size': original_image_size}
        print(sample)
        return sample

# Custom collate function to filter out None values
def custom_collate(batch):
    batch = [b for b in batch if b is not None]
    return default_collate(batch)

def load_data(img_dir, annotations_path, config ):

  with open(annotations_path) as f:
    annotations_data = json.load(f)

  # Define the transformations with resizing and augmentation
  transform = transforms.Compose([
      transforms.Resize((32, 32)),  # Resize the images to 256x256
      transforms.ToTensor(),
      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
      transforms.RandomHorizontalFlip(),  # Example augmentation
      # Add more augmentations if needed
  ])

  test_transform=transforms.Compose([
      transforms.ToTensor(),
      transforms.Resize((1920,1080)),
  ])

  # Create the dataset
  human_pose_dataset = HumanPoseDataset(annotations_data, img_dir, transform=transform)
  testing_pose_dataset = HumanPoseDataset(annotations_data, img_dir, transform=test_transform)

  train_size = int(0.8* len(human_pose_dataset))
  validation_size = int(0.1 * len(human_pose_dataset))
  test_size = len(human_pose_dataset) - train_size - validation_size
  train_dataset, remaining_dataset = random_split(human_pose_dataset, [train_size, validation_size + test_size])
  validation_dataset, test_dataset = random_split(remaining_dataset, [validation_size, test_size])

  test_pose_dataset , remaining_data = random_split(testing_pose_dataset,[6,194])



  # Create data loaders for each set with the custom collate function
  train_loader = DataLoader(train_dataset, batch_size= int(config["batch_size"]), shuffle=True, collate_fn=custom_collate)
  validation_loader = DataLoader(validation_dataset, batch_size= int(config["batch_size"]), shuffle=True, collate_fn=custom_collate)
  test_loader = DataLoader(test_dataset, batch_size = 8, shuffle=False, collate_fn=custom_collate)

  test_image_loader = DataLoader(test_pose_dataset, batch_size= 8, shuffle=False, collate_fn=custom_collate)

  return train_loader,validation_loader

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F

class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(32)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(64)
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.bn3 = nn.BatchNorm2d(128)
        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)
        self.bn4 = nn.BatchNorm2d(256)

        self.dropout1 = nn.Dropout(p=0.1)
        self.dropout2 = nn.Dropout(p=0.2)
        # Assuming the input image size is 32x32, after four pooling layers the image size will be 2x2
        self.fc1 = nn.Linear(256 * 2 * 2, 1024)
        self.bn_fc1 = nn.BatchNorm1d(1024)
        self.fc2 = nn.Linear(1024, 640)

        self.fc3 = nn.Linear(640, 33 * 4)  # Assuming 33 keypoints

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.bn1(x)
        x = self.pool(F.relu(self.conv2(x)))
        x = self.bn2(x)
        x = self.pool(F.relu(self.conv3(x)))
        x = self.bn3(x)
        x = self.pool(F.relu(self.conv4(x)))

        x = torch.flatten(x, 1)  # Flatten the tensor for the fully connected layer

        x = F.relu(self.fc1(x))
        #x = self.dropout1(x)
        x = F.relu(self.fc2(x))
        #x = self.dropout2(x)
        x = self.fc3(x)
        return x


# Initialize the model
model = SimpleCNN()
print("Model initialized.")
print(model)  # Print the model architecture

import os, tempfile
import ray.cloudpickle as pickle
from ray import train
from ray.train import Checkpoint
from ray import air
import ray
import io

def train(config, img_dir, annotations_path, ):

    if config['arch'] == 'cnn':
        model =  SimpleCNN()
    else:
        raise ValueError('Invalid architecture provided')

    criterion = nn.MSELoss()

    if config['opt']=='sgd':
      optimizer = optim.SGD(model.parameters(), lr=config['lr'], momentum=config['beta'], weight_decay=config['wd'])
    elif config['opt']=='adam':
        optimizer = optim.Adam(model.parameters(), lr=config['lr'], weight_decay=config['wd'])
    else:
        raise ValueError('Invalid optimizer provided')

    checkpoint = session.get_checkpoint()

    if checkpoint:
        with checkpoint.as_directory() as checkpoint_dir:
            checkpoint_path = os.path.join(checkpoint_dir, "checkpoint.pth")  # adjust filename as needed
            print(checkpoint_path)
            checkpoint_state = torch.load(checkpoint_path)
            start_epoch = checkpoint_state["epoch"]
            model.load_state_dict(checkpoint_state["model_state_dict"])
            optimizer.load_state_dict(checkpoint_state["optimizer_state_dict"])
    else:
        start_epoch = 0

    trainset, valset= load_data(img_dir, annotations_path, config )

    sample_batch = next(iter(trainset))
    images = sample_batch['image'].float()
    keypoints = sample_batch['keypoints'].view(-1, 132).float()


    validation_sample_batch = next(iter(valset))
    validation_images = validation_sample_batch['image'].float()
    validation_keypoints = validation_sample_batch['keypoints'].view(-1, 132).float()

    # train_loss = []
    # val_loss = []

    for epoch in range(start_epoch, 10):  # loop over the dataset multiple times

        optimizer.zero_grad()
        outputs = model(images)
        train_current_loss = criterion(outputs, keypoints)

        train_current_loss.backward()
        optimizer.step()

        model.eval()  # Switch to evaluation mode for validation
        with torch.no_grad():
            # Calculate validation loss
            val_outputs = model(validation_images)
            val_current_loss = criterion(val_outputs, validation_keypoints)



        checkpoint_data = {
            "epoch": epoch,
            "model_state_dict": model.state_dict(),
            "optimizer_state_dict": optimizer.state_dict(),
        }

        with tempfile.TemporaryDirectory() as tempdir:
            torch.save(
                checkpoint_data,
                os.path.join(tempdir, "checkpoint.pth"),
            )
            checkpoint = ray.train.Checkpoint.from_directory(tempdir)

            session.report(
                {"val_loss": val_current_loss.item() , "train_loss": train_current_loss.item()},
                checkpoint=checkpoint
            )
    print("Finished Training")

# Commented out IPython magic to ensure Python compatibility.
# %env RAY_AIR_NEW_OUTPUT=0

def main(num_samples=10, max_num_epochs=10):

    config = {
        "lr": tune.loguniform(1e-4, 1e-1),
        "opt":tune.grid_search(['sgd', 'adam']),
        "arch":tune.grid_search(['cnn']),
        "batch_size": tune.choice([4, 8,16]),
        "wd": tune.loguniform(1e-7, 1e-2),
        "beta": tune.grid_search([0.9, 0.95, 0.99, 0.999])
        }
    scheduler = ASHAScheduler(
        metric="val_loss",
        mode="min",
        max_t=max_num_epochs,
        grace_period=1,
        reduction_factor=2,
    )
    result = tune.run(
        partial(train, img_dir = '/content/drive/MyDrive/CNN_updated_Dataset', annotations_path = '/content/drive/MyDrive/annotations_CNN (3).json'),
        config = config,
        num_samples=num_samples,
        scheduler=scheduler,
        max_failures=1,
    )

    best_trial = result.get_best_trial(metric = "val_loss", mode = "min", scope = "avg")

    print(f"Best trial config: {best_trial.config}")
    print(f"Best trial final validation loss: {best_trial.last_result['val_loss']}")
    print(f"Best trial final train loss: {best_trial.last_result['train_loss']}")

    best_checkpoint = result.get_best_checkpoint(trial = best_trial, metric="val_loss", mode = 'min')
    print(best_checkpoint)

    # save the best_checkpoint , i want to use it's weights in future.

    print(best_checkpoint.get_metadata())

if __name__ == "__main__":
    main(num_samples=1, max_num_epochs=10)

# now training the model with best parameters

lr = 0.0019354854633145012
batch_size =  4
wd =  7.004873027399735e-05
beta =  0.95
opt= 'adam'









